{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Spark + DSE\n",
    "\n",
    "In BGDS, we advocate for the convination of the following tools as the best solution to address Big data's problems.\n",
    "\n",
    "- Apache Spark\n",
    "- Apache Cassandra (DSE)\n",
    "- Apache Solr (DSE)\n",
    "\n",
    "This notebook is an example of how to use these tools together to analyze the data crawled by the `Bovespa` example crawler included in the DaVinci distribution ().\n",
    "\n",
    "In order to be able to execute this notebook you will need first to start the `Bovespa` crawler and crawl all the data.\n",
    "\n",
    "```bash\n",
    "python manage.py crawl bovespa \\\n",
    "    --workers-num 10 \\\n",
    "    --chromium-bin-file '/Applications/Chromium.app/Contents/MacOS/Chromium' \\\n",
    "    --io-gs-project centering-badge-212119 \\\n",
    "    --cache-dir \"gs://davinci_example_bovespa\" \\\n",
    "    --local-dir \"fs:///data/bovespa/local\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/xalperte/anaconda/envs/notebooks/lib/python3.6/site-packages (0.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/xalperte/anaconda/envs/notebooks/lib/python3.6/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/xalperte/anaconda/envs/notebooks/lib/python3.6/site-packages (from pandas) (2019.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/xalperte/anaconda/envs/notebooks/lib/python3.6/site-packages (from pandas) (1.17.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/xalperte/anaconda/envs/notebooks/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Requirement already satisfied: pyspark in /Users/xalperte/anaconda/envs/notebooks/lib/python3.6/site-packages (2.4.4)\n",
      "Requirement already satisfied: py4j==0.10.7 in /Users/xalperte/anaconda/envs/notebooks/lib/python3.6/site-packages (from pyspark) (0.10.7)\n",
      "Requirement already satisfied: findspark in /Users/xalperte/anaconda/envs/notebooks/lib/python3.6/site-packages (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install pyspark\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find out where the pyspark\n",
    "import findspark\n",
    "findspark.init(\"/accounts/BGDS/servers/spark-2.4.4-bin-hadoop2.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations related to Cassandra connector & Cluster\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages datastax:spark-cassandra-connector:2.4.0-s_2.11 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Spark Context\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf() \\\n",
    " .setAppName(\"Factor Analysis Job\") \\\n",
    " .set(\"spark.cassandra.connection.host\", \"127.0.0.1\") \\\n",
    " .set(\"spark.sql.dse.search.enableOptimization\", \"on\") \n",
    "# .set(\"spark.cassandra.auth.username\", \"cassandra\") \\\n",
    "# .set(\"spark.cassandra.auth.password\", \"sQQE87Nt\")  \n",
    "\n",
    "# spark_master = \"spark://127.0.0.1:7077\"\n",
    "spark_master = \"local\"\n",
    "sc = SparkContext(spark_master, \"Factor Analysis Job\", conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating PySpark SQL Context\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for return a data frame attached to the informed keyspace.table\n",
    "def load_and_get_table_df(keys_space_name, table_name):\n",
    "    table_df = sqlContext.read \\\n",
    "        .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "        .options(table=table_name, keyspace=keys_space_name) \\\n",
    "        .option(\"spark.sql.dse.search.enableOptimization\", \"on\") \\\n",
    "        .load()\n",
    "    return table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-------------+------------------+--------------------+------------+--------------------+--------------+------------+----------+---------+----------+--------------------+\n",
      "|entity_type| ccvm|canceled_date|              cnpj|        company_name|company_type|          created_at|deleted_reason|granted_date|is_deleted|situation|solr_query|          updated_at|\n",
      "+-----------+-----+-------------+------------------+--------------------+------------+--------------------+--------------+------------+----------+---------+----------+--------------------+\n",
      "|    company| 1023|         null|00.000.000/0001-91|BANCO DO BRASIL S.A.|CIAS ABERTAS|2019-09-19 14:13:...|          null|  1977-07-20|     false|  GRANTED|      null|2019-09-19 14:13:...|\n",
      "|    company|10243|         null|83.296.889/0001-23|MASSA FALIDA DA S...|CIAS ABERTAS|2019-09-19 14:13:...|          null|  1979-11-30|     false|  GRANTED|      null|2019-09-19 14:13:...|\n",
      "|    company|10456|         null|61.079.117/0001-05|       ALPARGATAS SA|CIAS ABERTAS|2019-09-19 14:13:...|          null|  1977-07-20|     false|  GRANTED|      null|2019-09-19 14:13:...|\n",
      "|    company|10472|         null|60.500.139/0001-26|SARAIVA SA LIVREI...|CIAS ABERTAS|2019-09-19 14:13:...|          null|  1977-07-20|     false|  GRANTED|      null|2019-09-19 14:13:...|\n",
      "|    company|10561|         null|87.043.832/0001-73|SEIVA S.A. - FLOR...|CIAS ABERTAS|2019-09-19 14:13:...|          null|  1981-11-12|     false|  GRANTED|      null|2019-09-19 14:13:...|\n",
      "|    company|10880|         null|33.386.210/0001-19|SONDOTECNICA ENGE...|CIAS ABERTAS|2019-09-19 14:13:...|          null|  1980-08-19|     false|  GRANTED|      null|2019-09-19 14:13:...|\n",
      "|    company|10960|         null|92.929.520/0001-00|         SPRINGER SA|CIAS ABERTAS|2019-09-19 14:13:...|          null|  1968-10-24|     false|  GRANTED|      null|2019-09-19 14:13:...|\n",
      "|    company|11070|         null|33.228.024/0001-51|WLM INDÚSTRIA E C...|CIAS ABERTAS|2019-09-19 14:13:...|          null|  1971-07-01|     false|  GRANTED|      null|2019-09-19 14:13:...|\n",
      "|    company| 1120|         null|13.009.717/0001-46|BANCO DO ESTADO D...|CIAS ABERTAS|2019-09-19 14:13:...|          null|  1977-07-20|     false|  GRANTED|      null|2019-09-19 14:13:...|\n",
      "|    company|11207|         null|33.111.246/0001-90|TECNOSOLO S/A - E...|CIAS ABERTAS|2019-09-19 14:13:...|          null|  1977-07-20|     false|  GRANTED|      null|2019-09-19 14:13:...|\n",
      "+-----------+-----+-------------+------------------+--------------------+------------+--------------------+--------------+------------+----------+---------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "# Loading Bovespa companies table\n",
    "companies = load_and_get_table_df(\"davinci\", \"bovespa_company\")\n",
    "companies.filter(~col(\"situation\").eqNullSafe(\"CANCELED\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Filter NOT ('situation <=> CANCELED)\n",
      "+- Relation[entity_type#0,ccvm#1,canceled_date#2,cnpj#3,company_name#4,company_type#5,created_at#6,deleted_reason#7,granted_date#8,is_deleted#9,situation#10,solr_query#11,updated_at#12] org.apache.spark.sql.cassandra.CassandraSourceRelation@26188ac1\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "entity_type: string, ccvm: string, canceled_date: date, cnpj: string, company_name: string, company_type: string, created_at: timestamp, deleted_reason: string, granted_date: date, is_deleted: boolean, situation: string, solr_query: string, updated_at: timestamp\n",
      "Filter NOT (situation#10 <=> CANCELED)\n",
      "+- Relation[entity_type#0,ccvm#1,canceled_date#2,cnpj#3,company_name#4,company_type#5,created_at#6,deleted_reason#7,granted_date#8,is_deleted#9,situation#10,solr_query#11,updated_at#12] org.apache.spark.sql.cassandra.CassandraSourceRelation@26188ac1\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Filter NOT (situation#10 <=> CANCELED)\n",
      "+- Relation[entity_type#0,ccvm#1,canceled_date#2,cnpj#3,company_name#4,company_type#5,created_at#6,deleted_reason#7,granted_date#8,is_deleted#9,situation#10,solr_query#11,updated_at#12] org.apache.spark.sql.cassandra.CassandraSourceRelation@26188ac1\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Filter NOT (situation#10 <=> CANCELED)\n",
      "+- *(1) Scan org.apache.spark.sql.cassandra.CassandraSourceRelation@26188ac1 [entity_type#0,ccvm#1,canceled_date#2,cnpj#3,company_name#4,company_type#5,created_at#6,deleted_reason#7,granted_date#8,is_deleted#9,situation#10,solr_query#11,updated_at#12] PushedFilters: [Not(EqualNullSafe(situation,CANCELED))], ReadSchema: struct<entity_type:string,ccvm:string,canceled_date:date,cnpj:string,company_name:string,company_...\n"
     ]
    }
   ],
   "source": [
    "# Check the execution plan of the query\n",
    "companies.filter(~col(\"situation\").eqNullSafe(\"CANCELED\")).explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-------+-------+-------------------+--------------------+------------+--------+--------------------+--------------+----------+----------------+----------+--------------------+\n",
      "| ccvm|    period|version| number|financial_info_type|              amount|balance_type|comments|          created_at|deleted_reason|is_deleted|            name|solr_query|          updated_at|\n",
      "+-----+----------+-------+-------+-------------------+--------------------+------------+--------+--------------------+--------------+----------+----------------+----------+--------------------+\n",
      "|20532|2018-03-31|    3.0|      1|            INSTANT|709435311.0000000...|      ASSETS|    null|2019-09-20 12:02:...|          null|     false|     Ativo Total|      null|2019-09-20 12:02:...|\n",
      "|20532|2018-03-31|    3.0|   1.01|            INSTANT|424845041.0000000...|      ASSETS|    null|2019-09-20 12:02:...|          null|     false|Ativo Circulante|      null|2019-09-20 12:02:...|\n",
      "|20532|2018-03-31|    3.0|1.01.01|            INSTANT|10513279.00000000...|      ASSETS|    null|2019-09-20 12:02:...|          null|     false|Disponibilidades|      null|2019-09-20 12:02:...|\n",
      "+-----+----------+-------+-------+-------------------+--------------------+------------+--------+--------------------+--------------+----------+----------------+----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accessing to the fundamental data of the companies\n",
    "# Attaching a data frame to the accounting notes available in the database\n",
    "fundamentals = load_and_get_table_df(\"davinci\", \"bovespa_account\")\n",
    "fundamentals.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(asset='1023', astodate=datetime.date(2010, 12, 31), cap_ex_reported=Decimal('-35531943.000000000000000000'), total_assets=Decimal('3015311325.000000000000000000')),\n",
       " Row(asset='1023', astodate=datetime.date(2011, 3, 31), cap_ex_reported=Decimal('-544342.000000000000000000'), total_assets=Decimal('787908489.000000000000000000')),\n",
       " Row(asset='1023', astodate=datetime.date(2011, 6, 30), cap_ex_reported=Decimal('-3577161.000000000000000000'), total_assets=Decimal('816131152.000000000000000000')),\n",
       " Row(asset='1023', astodate=datetime.date(2011, 9, 30), cap_ex_reported=Decimal('-3949406.000000000000000000'), total_assets=Decimal('859280120.000000000000000000')),\n",
       " Row(asset='1023', astodate=datetime.date(2011, 12, 31), cap_ex_reported=Decimal('-76011460.000000000000000000'), total_assets=Decimal('5495055164.000000000000000000')),\n",
       " Row(asset='1023', astodate=datetime.date(2012, 3, 31), cap_ex_reported=Decimal('11179765.000000000000000000'), total_assets=Decimal('913866693.000000000000000000')),\n",
       " Row(asset='1023', astodate=datetime.date(2012, 6, 30), cap_ex_reported=Decimal('6103842.000000000000000000'), total_assets=Decimal('1925521806.000000000000000000')),\n",
       " Row(asset='1023', astodate=datetime.date(2012, 9, 30), cap_ex_reported=Decimal('-5454616.000000000000000000'), total_assets=Decimal('1009923655.000000000000000000')),\n",
       " Row(asset='1023', astodate=datetime.date(2012, 12, 31), cap_ex_reported=Decimal('-41643290.000000000000000000'), total_assets=Decimal('6469149446.000000000000000000')),\n",
       " Row(asset='1023', astodate=datetime.date(2013, 3, 31), cap_ex_reported=Decimal('-21592838.000000000000000000'), total_assets=Decimal('1105744898.000000000000000000'))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "\n",
    "#factors_df = fundamentals.filter(\n",
    "#    col(\"number\").isin([\"6.02\",\"1\"]) & col(\"ccvm\").isin([\"13773\", \"22306\", \"1023\", \"10472\"]))\n",
    "\n",
    "# Get the Capital Expenditures from the Fundamentals\n",
    "# Account 1    = Total Assets of the company\n",
    "# Account 6.02 = Capital Expenditure reported by the company during the period\n",
    "factors_df = fundamentals.filter(\n",
    "    col(\"number\").isin([\"6.02\", \"1\"]))\n",
    "factors_df = factors_df.withColumn(\n",
    "    \"factor_name\", when(factors_df.number == \"1\", \"total_assets\").otherwise(\"cap_ex_reported\"))\n",
    "\n",
    "factors_df = factors_df\\\n",
    "    .select(col(\"ccvm\").alias(\"asset\"), \n",
    "            col(\"period\").alias(\"astodate\"),\n",
    "            col(\"factor_name\"), \n",
    "            col(\"amount\").alias(\"amount\"))\n",
    "\n",
    "factors_df = factors_df.groupby(col(\"asset\"), col(\"astodate\"))\\\n",
    "    .pivot(\"factor_name\").sum(\"amount\").orderBy(\"asset\", \"astodate\")\n",
    "\n",
    "factors_df = factors_df.withColumn(\n",
    "    \"cap_ex_reported_scaled\", \n",
    "    when(factors_df.cap_ex_reported > 0, 0).otherwise(abs(factors_df.cap_ex_reported)) / factors_df.total_assets)\n",
    "\n",
    "factors_df = factors_df.withColumn(\"capex_vol_6q\", stddev(col(\"cap_ex_reported_scaled\"))\n",
    "             .over(Window.partitionBy(\"asset\").rowsBetween(-5, 0)) )\n",
    "\n",
    "factors_df = factors_df.withColumn(\"capex_vol_6q_ranked\", rank()\\\n",
    "             .over(Window.partitionBy(\"astodate\").orderBy(asc(\"capex_vol_6q\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+-------------------+\n",
      "|  astodate|asset|        capex_vol_6q|capex_vol_6q_ranked|\n",
      "+----------+-----+--------------------+-------------------+\n",
      "|2018-06-30|18333|                 0.0|                  1|\n",
      "|2018-06-30|15741|                 0.0|                  1|\n",
      "|2018-06-30|17493|                 0.0|                  1|\n",
      "|2018-06-30|17884|                 0.0|                  1|\n",
      "|2018-06-30|13447|                 0.0|                  1|\n",
      "|2018-06-30|10561|                 0.0|                  1|\n",
      "|2018-06-30|19747|                 0.0|                  1|\n",
      "|2018-06-30|16942|                 0.0|                  1|\n",
      "|2018-06-30|15458|                 0.0|                  1|\n",
      "|2018-06-30|17914|                 0.0|                  1|\n",
      "|2018-06-30|19640|                 0.0|                  1|\n",
      "|2018-06-30|17434|                 0.0|                  1|\n",
      "|2018-06-30|11207|                 0.0|                  1|\n",
      "|2018-06-30|12530|                 0.0|                  1|\n",
      "|2018-06-30|15733|                 0.0|                  1|\n",
      "|2018-06-30|18554|                 0.0|                  1|\n",
      "|2018-06-30|15695|                 0.0|                  1|\n",
      "|2018-06-30|16446|                 0.0|                  1|\n",
      "|2018-06-30|16497|                 0.0|                  1|\n",
      "|2018-06-30|15717|                 0.0|                  1|\n",
      "|2018-06-30|18406|                 0.0|                  1|\n",
      "|2018-06-30| 1724|                 0.0|                  1|\n",
      "|2018-06-30|14303|                 0.0|                  1|\n",
      "|2018-06-30|19313|                 0.0|                  1|\n",
      "|2018-06-30|16438|                 0.0|                  1|\n",
      "|2018-06-30|16551|                 0.0|                  1|\n",
      "|2018-06-30|16624|                 0.0|                  1|\n",
      "|2018-06-30|17388|                 0.0|                  1|\n",
      "|2018-06-30|15865|                 0.0|                  1|\n",
      "|2018-06-30|16560|                 0.0|                  1|\n",
      "|2018-06-30|14320|                 0.0|                  1|\n",
      "|2018-06-30|17540|                 0.0|                  1|\n",
      "|2018-06-30|11215|                 0.0|                  1|\n",
      "|2018-06-30|16586|                 0.0|                  1|\n",
      "|2018-06-30|15784|2.154684818405389...|                 35|\n",
      "|2018-06-30|11223|9.109701788020652E-5|                 36|\n",
      "|2018-06-30|19429|3.786685445962823E-4|                 37|\n",
      "|2018-06-30|16993|4.126095814043424...|                 38|\n",
      "|2018-06-30| 1120|7.714062483542637E-4|                 39|\n",
      "|2018-06-30|17868| 9.45748962463084E-4|                 40|\n",
      "|2018-06-30|19836|0.001161058138079...|                 41|\n",
      "|2018-06-30|10960|0.001520622197216...|                 42|\n",
      "|2018-06-30|16772|0.001922849448084...|                 43|\n",
      "|2018-06-30|19658|0.002273040049507...|                 44|\n",
      "|2018-06-30| 1171|0.002598364825552...|                 45|\n",
      "|2018-06-30|19844|0.002615755168206688|                 46|\n",
      "|2018-06-30|18589|0.002616067099037...|                 47|\n",
      "|2018-06-30|17892|0.002690063822043...|                 48|\n",
      "|2018-06-30|16373|0.002708192195296...|                 49|\n",
      "|2018-06-30|15822|0.002731878309881...|                 50|\n",
      "|2018-06-30| 1023|0.002802563855948...|                 51|\n",
      "|2018-06-30| 1562|0.004409109388527348|                 52|\n",
      "|2018-06-30|15407|0.004603734484090063|                 53|\n",
      "|2018-06-30|18708|0.004619674653046467|                 54|\n",
      "|2018-06-30|19437|0.005241499801265537|                 55|\n",
      "|2018-06-30|13471|0.005418085184515529|                 56|\n",
      "|2018-06-30|18538|0.006378619150464046|                 57|\n",
      "|2018-06-30|10456|0.006685037035549367|                 58|\n",
      "|2018-06-30|13366|0.008151267230723494|                 59|\n",
      "|2018-06-30|11070|0.008174996817532509|                 60|\n",
      "|2018-06-30|18376|0.008418505055332964|                 61|\n",
      "|2018-06-30|13439|0.008538196312258618|                 62|\n",
      "|2018-06-30|14460|0.008690381359104252|                 63|\n",
      "|2018-06-30| 1597| 0.00892838282482705|                 64|\n",
      "|2018-06-30|10472|  0.0092729934918558|                 65|\n",
      "|2018-06-30|19763|0.009286928340414821|                 66|\n",
      "|2018-06-30|19330| 0.00936663286352145|                 67|\n",
      "|2018-06-30|14311| 0.00945515160639955|                 68|\n",
      "|2018-06-30|20362|0.010023842796053816|                 69|\n",
      "|2018-06-30|18953|0.010120069197721262|                 70|\n",
      "|2018-06-30|19348| 0.01066209107070466|                 71|\n",
      "|2018-06-30|18309|0.010997689169396755|                 72|\n",
      "|2018-06-30|19470|0.011758088892332801|                 73|\n",
      "|2018-06-30|19453|0.011856957310653803|                 74|\n",
      "|2018-06-30|18546|0.012936910321505157|                 75|\n",
      "|2018-06-30|18660|0.012955681035746442|                 76|\n",
      "|2018-06-30|16608|0.014135490517370336|                 77|\n",
      "|2018-06-30|18775|0.014262139396551509|                 78|\n",
      "|2018-06-30|14451|0.014363506294309433|                 79|\n",
      "|2018-06-30|21393|0.014937513059408518|                 80|\n",
      "|2018-06-30|11312|0.015241802120046914|                 81|\n",
      "|2018-06-30|14443|0.015603088174033584|                 82|\n",
      "|2018-06-30|11398|0.015822611866144812|                 83|\n",
      "|2018-06-30|14346|  0.0161749475176892|                 84|\n",
      "|2018-06-30|19445| 0.01656514880907101|                 85|\n",
      "|2018-06-30|17850|0.017176769005452296|                 86|\n",
      "|2018-06-30|19364|0.017182849794683847|                 87|\n",
      "|2018-06-30|18465| 0.01744237356267776|                 88|\n",
      "|2018-06-30|11231| 0.01794103641097693|                 89|\n",
      "|2018-06-30|15539|0.018233217408528495|                 90|\n",
      "|2018-06-30|16985|   0.019000688313848|                 91|\n",
      "|2018-06-30| 1570| 0.02153695570563924|                 92|\n",
      "|2018-06-30| 1694|0.021670764134350838|                 93|\n",
      "|2018-06-30|11258|0.021820176400906263|                 94|\n",
      "|2018-06-30|18368|0.022423327537782315|                 95|\n",
      "|2018-06-30| 1155|0.022717851269431273|                 96|\n",
      "|2018-06-30|10880|0.023236267948331692|                 97|\n",
      "|2018-06-30|15342| 0.02338837777543938|                 98|\n",
      "|2018-06-30|17671| 0.02520266776090711|                 99|\n",
      "|2018-06-30|16616|0.026606660486928207|                100|\n",
      "+----------+-----+--------------------+-------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "factors_df.select(col(\"astodate\"), col(\"asset\"), col(\"capex_vol_6q\"), col(\"capex_vol_6q_ranked\")).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[asset: string, astodate: date, cap_ex_reported: decimal(38,18), total_assets: decimal(38,18), cap_ex_reported_scaled: decimal(38,6), capex_vol_6q: double, capex_vol_6q_ranked: int]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_w(col, w):\n",
    "    avg_ = avg(col).over(w)\n",
    "    avg_sq = avg(col * col).over(w)\n",
    "    sd_ = sqrt(avg_sq - avg_ * avg_)\n",
    "    return (col - avg_) / sd_\n",
    "\n",
    "w = Window().partitionBy(\"astodate\")\n",
    "factors_df_standard = factors_df.withColumn(\"capex_vol_6q_ranked_zscored\", \n",
    "                                            z_score_w(factors_df.capex_vol_6q_ranked, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---------------------------+\n",
      "|  astodate|asset|capex_vol_6q_ranked_zscored|\n",
      "+----------+-----+---------------------------+\n",
      "|2018-06-30|18333|        -1.3876010849394778|\n",
      "|2018-06-30|15741|        -1.3876010849394778|\n",
      "|2018-06-30|17493|        -1.3876010849394778|\n",
      "|2018-06-30|17884|        -1.3876010849394778|\n",
      "|2018-06-30|13447|        -1.3876010849394778|\n",
      "|2018-06-30|10561|        -1.3876010849394778|\n",
      "|2018-06-30|19747|        -1.3876010849394778|\n",
      "|2018-06-30|16942|        -1.3876010849394778|\n",
      "|2018-06-30|15458|        -1.3876010849394778|\n",
      "|2018-06-30|17914|        -1.3876010849394778|\n",
      "|2018-06-30|19640|        -1.3876010849394778|\n",
      "|2018-06-30|17434|        -1.3876010849394778|\n",
      "|2018-06-30|11207|        -1.3876010849394778|\n",
      "|2018-06-30|12530|        -1.3876010849394778|\n",
      "|2018-06-30|15733|        -1.3876010849394778|\n",
      "|2018-06-30|18554|        -1.3876010849394778|\n",
      "|2018-06-30|15695|        -1.3876010849394778|\n",
      "|2018-06-30|16446|        -1.3876010849394778|\n",
      "|2018-06-30|16497|        -1.3876010849394778|\n",
      "|2018-06-30|15717|        -1.3876010849394778|\n",
      "|2018-06-30|18406|        -1.3876010849394778|\n",
      "|2018-06-30| 1724|        -1.3876010849394778|\n",
      "|2018-06-30|14303|        -1.3876010849394778|\n",
      "|2018-06-30|19313|        -1.3876010849394778|\n",
      "|2018-06-30|16438|        -1.3876010849394778|\n",
      "|2018-06-30|16551|        -1.3876010849394778|\n",
      "|2018-06-30|16624|        -1.3876010849394778|\n",
      "|2018-06-30|17388|        -1.3876010849394778|\n",
      "|2018-06-30|15865|        -1.3876010849394778|\n",
      "|2018-06-30|16560|        -1.3876010849394778|\n",
      "|2018-06-30|14320|        -1.3876010849394778|\n",
      "|2018-06-30|17540|        -1.3876010849394778|\n",
      "|2018-06-30|11215|        -1.3876010849394778|\n",
      "|2018-06-30|16586|        -1.3876010849394778|\n",
      "|2018-06-30|15784|        -0.5822702402125067|\n",
      "|2018-06-30|11223|        -0.5585840388970076|\n",
      "|2018-06-30|19429|        -0.5348978375815084|\n",
      "|2018-06-30|16993|        -0.5112116362660093|\n",
      "|2018-06-30| 1120|        -0.4875254349505101|\n",
      "|2018-06-30|17868|       -0.46383923363501095|\n",
      "|2018-06-30|19836|        -0.4401530323195118|\n",
      "|2018-06-30|10960|       -0.41646683100401266|\n",
      "|2018-06-30|16772|        -0.3927806296885135|\n",
      "|2018-06-30|19658|       -0.36909442837301437|\n",
      "|2018-06-30| 1171|        -0.3454082270575152|\n",
      "|2018-06-30|19844|        -0.3217220257420161|\n",
      "|2018-06-30|18589|       -0.29803582442651694|\n",
      "|2018-06-30|17892|        -0.2743496231110178|\n",
      "|2018-06-30|16373|        -0.2506634217955186|\n",
      "|2018-06-30|15822|       -0.22697722048001948|\n",
      "|2018-06-30| 1023|       -0.20329101916452033|\n",
      "|2018-06-30| 1562|       -0.17960481784902116|\n",
      "|2018-06-30|15407|       -0.15591861653352201|\n",
      "|2018-06-30|18708|       -0.13223241521802287|\n",
      "|2018-06-30|19437|       -0.10854621390252372|\n",
      "|2018-06-30|13471|       -0.08486001258702457|\n",
      "|2018-06-30|18538|       -0.06117381127152542|\n",
      "|2018-06-30|10456|       -0.03748760995602627|\n",
      "|2018-06-30|13366|       -0.01380140864052...|\n",
      "|2018-06-30|11070|       0.009884792674972026|\n",
      "|2018-06-30|18376|        0.03357099399047118|\n",
      "|2018-06-30|13439|        0.05725719530597032|\n",
      "|2018-06-30|14460|        0.08094339662146947|\n",
      "|2018-06-30| 1597|        0.10462959793696862|\n",
      "|2018-06-30|10472|        0.12831579925246778|\n",
      "|2018-06-30|19763|        0.15200200056796692|\n",
      "|2018-06-30|19330|        0.17568820188346607|\n",
      "|2018-06-30|14311|         0.1993744031989652|\n",
      "|2018-06-30|20362|        0.22306060451446438|\n",
      "|2018-06-30|18953|        0.24674680582996353|\n",
      "|2018-06-30|19348|        0.27043300714546264|\n",
      "|2018-06-30|18309|        0.29411920846096185|\n",
      "|2018-06-30|19470|          0.317805409776461|\n",
      "|2018-06-30|19453|        0.34149161109196013|\n",
      "|2018-06-30|18546|         0.3651778124074593|\n",
      "|2018-06-30|18660|         0.3888640137229584|\n",
      "|2018-06-30|16608|        0.41255021503845757|\n",
      "|2018-06-30|18775|         0.4362364163539567|\n",
      "|2018-06-30|14451|        0.45992261766945586|\n",
      "|2018-06-30|21393|          0.483608818984955|\n",
      "|2018-06-30|11312|         0.5072950203004541|\n",
      "|2018-06-30|14443|         0.5309812216159533|\n",
      "|2018-06-30|11398|         0.5546674229314524|\n",
      "|2018-06-30|14346|         0.5783536242469516|\n",
      "|2018-06-30|19445|         0.6020398255624507|\n",
      "|2018-06-30|17850|         0.6257260268779499|\n",
      "|2018-06-30|19364|          0.649412228193449|\n",
      "|2018-06-30|18465|         0.6730984295089482|\n",
      "|2018-06-30|11231|         0.6967846308244474|\n",
      "|2018-06-30|15539|         0.7204708321399466|\n",
      "|2018-06-30|16985|         0.7441570334554457|\n",
      "|2018-06-30| 1570|         0.7678432347709448|\n",
      "|2018-06-30| 1694|          0.791529436086444|\n",
      "|2018-06-30|11258|         0.8152156374019431|\n",
      "|2018-06-30|18368|         0.8389018387174423|\n",
      "|2018-06-30| 1155|         0.8625880400329414|\n",
      "|2018-06-30|10880|         0.8862742413484406|\n",
      "|2018-06-30|15342|         0.9099604426639397|\n",
      "|2018-06-30|17671|         0.9336466439794389|\n",
      "|2018-06-30|16616|          0.957332845294938|\n",
      "+----------+-----+---------------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "factors_df_standard.select(\n",
    "    col(\"astodate\"), \n",
    "    col(\"asset\"), \n",
    "    col(\"capex_vol_6q_ranked_zscored\")).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_data = factors_df_standard.select(\n",
    "    col(\"astodate\"), \n",
    "    col(\"asset\"), \n",
    "    col(\"capex_vol_6q_ranked_zscored\").alias(\"capex_vol_6q\")).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persist the results\n",
    "\n",
    "Now it's time to save the factor into a table. To do this, the system should had create a \n",
    "keyspace for us in the database. The keyspace should have the same TOKEN than the one used\n",
    "to connect through the API.\n",
    "\n",
    "Each user will have it's own space in the system to run the analyses.\n",
    "\n",
    "```sql\n",
    "CREATE KEYSPACE IF NOT EXISTS <USER_ID>_analysis WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 1};\n",
    "```\n",
    "\n",
    "with full access to it:\n",
    "\n",
    "```sql\n",
    "-- Create the user using the token and\n",
    "CREATE ROLE user_<USER_ID> WITH PASSWORD = '<USER_TOKEN>' AND LOGIN = true AND SUPERUSER = false;\n",
    "\n",
    "-- Grant all permission for the user keyspace\n",
    "GRANT ALL PERMISSIONS IN KEYSPACE <USER_ID>_analysis to user_<USER_ID>;\n",
    "```\n",
    "\n",
    "PRO features:\n",
    "- Allow replication of data (ReplicationFactor = 3)\n",
    "    ```sql\n",
    "    CREATE KEYSPACE IF NOT EXISTS <TOKEN>_analysis WITH replication = {'class': 'SimpleStrategy', 'replication_factor' : 3};\n",
    "    ```\n",
    "- Network replication (multiple DataCenters)\n",
    "    ```sql\n",
    "    CREATE KEYSPACE IF NOT EXISTS <TOKEN>_analysis WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1' : 2, 'DC2': 3, 'DC3': 2};\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from dse.cluster import Cluster\n",
    "    from dse.auth import DSEPlainTextAuthProvider\n",
    "except ImportError:\n",
    "    from cassandra.cluster import Cluster\n",
    "    from cassandra.auth import DSEPlainTextAuthProvider\n",
    "\n",
    "# auth_provider = DSEPlainTextAuthProvider('cassandra', 'xxxx')\n",
    "\n",
    "#cluster = Cluster(['10.154.0.6', '10.154.0.3'], auth_provider=auth_provider)  # provide contact points and port\n",
    "cluster = Cluster(['127.0.0.1'])  # provide contact points and port\n",
    "session = cluster.connect('xalperte_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xalperte/anaconda/envs/notebooks/lib/python3.6/site-packages/dse/cqlengine/management.py:540: UserWarning: CQLENG_ALLOW_SCHEMA_MANAGEMENT environment variable is not set. Future versions of this package will require this variable to enable management functions.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from dse.cqlengine.models import Model\n",
    "    from dse.cqlengine import columns\n",
    "    from dse.cqlengine.management import sync_table\n",
    "    from dse.cqlengine.connection import register_connection\n",
    "except ImportError:\n",
    "    from cassandra.cqlengine.models import Model\n",
    "    from cassandra.cqlengine import columns\n",
    "    from cassandra.cqlengine.management import sync_table\n",
    "    from cassandra.cqlengine.connection import register_connection\n",
    "    \n",
    "from pyspark.sql.types import StringType, DateType, TimestampType\n",
    "from pyspark.sql.types import FloatType, DecimalType, DoubleType\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def create_cassandra_model(schema, table_name, primary_colums=None):\n",
    "    class MyModel(object):\n",
    "        pass\n",
    "\n",
    "    if not isinstance(primary_colums, list):\n",
    "        primary_colums = [primary_colums]\n",
    "        \n",
    "    df_fields = {}\n",
    "    for field in schema.fields:\n",
    "        df_fields[field.name] = field\n",
    "        \n",
    "    metadata = {\n",
    "        \"__table_name__\": table_name\n",
    "    }\n",
    "        \n",
    "    # First the primary keys\n",
    "    for field_name in primary_colums:\n",
    "        field = df_fields[field_name]\n",
    "        if isinstance(field.dataType, StringType):\n",
    "            metadata[field_name] = columns.Text(required=(not field.nullable), primary_key=True)\n",
    "        if isinstance(field.dataType, DateType):\n",
    "            metadata[field_name] = columns.Date(required=(not field.nullable), primary_key=True)\n",
    "        if isinstance(field.dataType, TimestampType):\n",
    "            metadata[field_name] = columns.DateTime(required=(not field.nullable), primary_key=True)\n",
    "        if isinstance(field.dataType, DoubleType):\n",
    "            metadata[field_name] = columns.Double(required=(not field.nullable), primary_key=True)\n",
    "        if isinstance(field.dataType, DecimalType):\n",
    "            metadata[field_name] = columns.Decimal(required=(not field.nullable), primary_key=True)\n",
    "        if isinstance(field.dataType, FloatType):\n",
    "            metadata[field_name] = columns.Float(required=(not field.nullable), primary_key=True)\n",
    "        if isinstance(field.dataType, IntegerType):\n",
    "            metadata[field_name] = columns.Integer(required=(not field.nullable), primary_key=True)\n",
    "\n",
    "    # First the primary keys\n",
    "    for field_name, field in df_fields.items():\n",
    "        if field_name not in primary_colums:\n",
    "            if isinstance(field.dataType, StringType):\n",
    "                metadata[field_name] = columns.Text(required=(not field.nullable), primary_key=False)\n",
    "            if isinstance(field.dataType, DateType):\n",
    "                metadata[field_name] = columns.Date(required=(not field.nullable), primary_key=False)\n",
    "            if isinstance(field.dataType, TimestampType):\n",
    "                metadata[field_name] = columns.DateTime(required=(not field.nullable), primary_key=False)\n",
    "            if isinstance(field.dataType, DoubleType):\n",
    "                metadata[field_name] = columns.Double(required=(not field.nullable), primary_key=False)\n",
    "            if isinstance(field.dataType, DecimalType):\n",
    "                metadata[field_name] = columns.Decimal(required=(not field.nullable), primary_key=False)\n",
    "            if isinstance(field.dataType, FloatType):\n",
    "                metadata[field_name] = columns.Float(required=(not field.nullable), primary_key=False)\n",
    "            if isinstance(field.dataType, IntegerType):\n",
    "                metadata[field_name] = columns.Integer(required=(not field.nullable), primary_key=False)\n",
    "\n",
    "    return type('MyModel', (Model,), metadata)\n",
    "            \n",
    "            \n",
    "model = create_cassandra_model(factors_df_standard.schema, \"capex_vol_6q\", \"asset\")\n",
    "register_connection(\"my_connection\", session=session)\n",
    "sync_table(model, keyspaces=[\"xalperte_analysis\"], connections=[\"my_connection\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_df.write\\\n",
    "    .format(\"org.apache.spark.sql.cassandra\")\\\n",
    "    .options(table=\"capex_vol_6q\", keyspace=\"xalperte_analysis\")\\\n",
    "    .option(\"confirm.truncate\",\"true\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .partitionBy(\"astodate\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>capex_vol_6q</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>astodate</th>\n",
       "      <th>asset</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">2018-06-30</td>\n",
       "      <td>18333</td>\n",
       "      <td>-1.387601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15741</td>\n",
       "      <td>-1.387601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17493</td>\n",
       "      <td>-1.387601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17884</td>\n",
       "      <td>-1.387601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13447</td>\n",
       "      <td>-1.387601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">2012-03-31</td>\n",
       "      <td>17558</td>\n",
       "      <td>1.547964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18597</td>\n",
       "      <td>1.566004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19437</td>\n",
       "      <td>1.584044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17493</td>\n",
       "      <td>1.602084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16446</td>\n",
       "      <td>1.620123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5328 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  capex_vol_6q\n",
       "astodate   asset              \n",
       "2018-06-30 18333     -1.387601\n",
       "           15741     -1.387601\n",
       "           17493     -1.387601\n",
       "           17884     -1.387601\n",
       "           13447     -1.387601\n",
       "...                        ...\n",
       "2012-03-31 17558      1.547964\n",
       "           18597      1.566004\n",
       "           19437      1.584044\n",
       "           17493      1.602084\n",
       "           16446      1.620123\n",
       "\n",
       "[5328 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "factors_data.set_index(['astodate', 'asset'], inplace=True)\n",
    "display(factors_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>capex_vol_6q</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>astodate</th>\n",
       "      <th>asset</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">1.530317e+09</td>\n",
       "      <td>15741</td>\n",
       "      <td>-1.230409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16772</td>\n",
       "      <td>-1.230409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12530</td>\n",
       "      <td>-1.230409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16446</td>\n",
       "      <td>-1.230409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16497</td>\n",
       "      <td>-1.230409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">1.333152e+09</td>\n",
       "      <td>15369</td>\n",
       "      <td>1.167572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16527</td>\n",
       "      <td>1.280437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15822</td>\n",
       "      <td>1.393302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16624</td>\n",
       "      <td>1.506167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16446</td>\n",
       "      <td>1.619033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>910 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    capex_vol_6q\n",
       "astodate     asset              \n",
       "1.530317e+09 15741     -1.230409\n",
       "             16772     -1.230409\n",
       "             12530     -1.230409\n",
       "             16446     -1.230409\n",
       "             16497     -1.230409\n",
       "...                          ...\n",
       "1.333152e+09 15369      1.167572\n",
       "             16527      1.280437\n",
       "             15822      1.393302\n",
       "             16624      1.506167\n",
       "             16446      1.619033\n",
       "\n",
       "[910 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "unixt_factors_data = factors_data.set_index(pd.MultiIndex.from_tuples(\n",
    "    [(x.timestamp(), y) for x, y in factors_data.index.values],\n",
    "    names=['astodate', 'asset']))\n",
    "display(unixt_factors_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
